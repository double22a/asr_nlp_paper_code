
## language model

- [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860), Zihang Dai et al, 1901


## data augmentation

- [Data Augmentation Approaches in Natural Language Processing: A Survey](https://arxiv.org/abs/2110.01852), Bohan Li et al, 2110

## prompt

- [Must-read papers on prompt-based tuning for pre-trained language models](https://github.com/thunlp/PromptPapers), Ning Ding and Shengding Hu, 2201

## transformer

- [Transformer Quality in Linear Time](https://arxiv.org/pdf/2202.10447.pdf), Google, Weizhe Hua et al, 2202

