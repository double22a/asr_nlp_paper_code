# ASR Paper

## transformer

- [Transformers with convolutional context for ASR](https://arxiv.org/abs/1904.11660), Abdelrahman Mohamed et al, 1904 

- [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100), Anmol Gulati et al, 2005

- [SIMPLIFIED SELF-ATTENTION FOR TRANSFORMER-BASED END-TO-END SPEECH RECOGNITION](https://arxiv.org/abs/2005.10463), Haoneng Luo et al, 2005

- [Advanced Long-context End-to-end Speech Recognition Using Context-expanded Transformers](https://arxiv.org/abs/2104.09426), Takaaki Hori et al, 2104

- [A Survey of Transformers](https://arxiv.org/abs/2106.04554), Tianyang Lin et al, 2106

## transducer

- [TRANSFORMER-TRANSDUCER: END-TO-END SPEECH RECOGNITION WITH SELF-ATTENTION](https://arxiv.org/abs/1910.12977), Ching-Feng Yeh et al, 1910

- [IMPROVING ACCURACY OF RARE WORDS FOR RNN-TRANSDUCER THROUGH UNIGRAM SHALLOW FUSION](https://arxiv.org/abs/2012.00133), Vijay Ravi et al, 2012

- [LESS IS MORE: IMPROVED RNN-T DECODING USING LIMITED LABEL CONTEXT AND PATH MERGING](https://arxiv.org/abs/2012.06749), Rohit Prabhavalkar et al, 2012

## streaming

- [A BETTER AND FASTER END-TO-END MODEL FOR STREAMING ASR](https://arxiv.org/abs/2011.10798), Bo Li et al, 2011

- [Bridging the gap between streaming and non-streaming ASR systems by distilling ensembles of CTC and RNN-T models](https://arxiv.org/abs/2104.14346), Thibault Doutre et al, 2104

- [Reducing Streaming ASR Model Delay with Self Alignment](https://arxiv.org/abs/2105.05005), Jaeyoung Kim et al, 2105

- [Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models](https://arxiv.org/abs/2107.09428), Tianzi Wang et al, 2107

## contextual

- [HYBRID AUTOREGRESSIVE TRANSDUCER (HAT)](https://arxiv.org/abs/2003.07705), Ehsan Variani et al, 2003

- [Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion](https://arxiv.org/abs/2104.02194), Duc Le et al, 2104

- [Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition](https://arxiv.org/abs/2109.00627), Guangzhi Sun et al, 2109
