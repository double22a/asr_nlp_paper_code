# ASR Paper

## data augmentation

- [SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/pdf/1904.08779.pdf), Daniel S. Park et al, Google, 1904

- [SPLICEOUT: A Simple and Efficient Audio Augmentation Method](https://arxiv.org/pdf/2110.00046.pdf), Arjit Jain et al, 2109

## CTC

- [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf), Alex Graves et al, 0601

- [SCALA: SUPERVISED CONTRASTIVE LEARNING FOR END-TO-END AUTOMATIC SPEECH RECOGNITION](https://arxiv.org/pdf/2110.04187.pdf), Li Fu et al, 2110

## transformer & attention based

- [Transformers with convolutional context for ASR](https://arxiv.org/abs/1904.11660), Abdelrahman Mohamed et al, Facebook, 1904 

- [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100), Anmol Gulati et al, Google, 2005

- [SIMPLIFIED SELF-ATTENTION FOR TRANSFORMER-BASED END-TO-END SPEECH RECOGNITION](https://arxiv.org/abs/2005.10463), Haoneng Luo et al, 2005

- [Advanced Long-context End-to-end Speech Recognition Using Context-expanded Transformers](https://arxiv.org/abs/2104.09426), Takaaki Hori et al, 2104

- [A Survey of Transformers](https://arxiv.org/abs/2106.04554), Tianyang Lin et al, 2106

- [3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech recognition](https://arxiv.org/pdf/2204.03178.pdf), Zhao You et al, 2204

## streaming & attention based

- [A BETTER AND FASTER END-TO-END MODEL FOR STREAMING ASR](https://arxiv.org/abs/2011.10798), Bo Li et al, 2011

- [Bridging the gap between streaming and non-streaming ASR systems by distilling ensembles of CTC and RNN-T models](https://arxiv.org/abs/2104.14346), Thibault Doutre et al, 2104

- [Reducing Streaming ASR Model Delay with Self Alignment](https://arxiv.org/abs/2105.05005), Jaeyoung Kim et al, 2105

- [Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models](https://arxiv.org/abs/2107.09428), Tianzi Wang et al, 2107

## transducer

- [TRANSFORMER-TRANSDUCER: END-TO-END SPEECH RECOGNITION WITH SELF-ATTENTION](https://arxiv.org/abs/1910.12977), Ching-Feng Yeh et al, 1910

- [IMPROVING ACCURACY OF RARE WORDS FOR RNN-TRANSDUCER THROUGH UNIGRAM SHALLOW FUSION](https://arxiv.org/abs/2012.00133), Vijay Ravi et al, 2012

- [LESS IS MORE: IMPROVED RNN-T DECODING USING LIMITED LABEL CONTEXT AND PATH MERGING](https://arxiv.org/abs/2012.06749), Rohit Prabhavalkar et al, 2012

- [INPUT LENGTH MATTERS: AN EMPIRICAL STUDY OF RNN-T AND MWER TRAINING FOR LONG-FORM TELEPHONY SPEECH RECOGNITION](https://arxiv.org/pdf/2110.03841.pdf), Zhiyun Lu et al, 2110


## cascaded

- [Modular End-to-end Automatic Speech Recognition Framework for Acoustic-to-word Model](https://arxiv.org/pdf/2008.00953.pdf), Qi Liu et al, 2008

- [TRANSFORMER TRANSDUCER: ONE MODEL UNIFYING STREAMING AND NON-STREAMING SPEECH RECOGNITION](https://arxiv.org/abs/2010.03192), Anshuman Tripathi et al, 2010

- [UNIVERSAL ASR: UNIFYING STREAMING AND NON-STREAMING ASR USING A SINGLE ENCODER-DECODER MODEL](https://arxiv.org/abs/2010.14099), Zhifu Gao et al, 2010

- [CASCADED ENCODERS FOR UNIFYING STREAMING AND NON-STREAMING ASR](https://arxiv.org/abs/2010.14606), Arun Narayanan et al, 2010

- [CASCADE RNN-TRANSDUCER: SYLLABLE BASED STREAMING ON-DEVICE MANDARIN SPEECH RECOGNITION WITH A SYLLABLE-TO-CHARACTER CONVERTER](https://arxiv.org/abs/2011.08469), Xiong Wang et al, 2011

- [Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition](https://arxiv.org/abs/2012.05481), Binbin Zhang, 2012

- [TRANSFORMER BASED DELIBERATION FOR TWO-PASS SPEECH RECOGNITION](https://arxiv.org/abs/2101.11577), Ke Hu et al, 2101

- [TSNAT: Two-Step Non-Autoregressvie Transformer Models for Speech Recognition](https://arxiv.org/abs/2104.01522), Zhengkun Tian et al, 2104

- [DECOUPLING RECOGNITION AND TRANSCRIPTION IN MANDARIN ASR](https://arxiv.org/abs/2108.01129), Jiahong Yuan et al, 2108

- [Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition](https://arxiv.org/abs/2110.04891), Guoli Ye et al, 2110

- [A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes](https://arxiv.org/pdf/2204.06164v1.pdf), Shaojin Ding et al, Google, 2204

- [LEARNING A DUAL-MODE SPEECH RECOGNITION MODEL VIA SELF-PRUNING](https://arxiv.org/pdf/2207.11906.pdf), Chunxi Liu el al, Facebook, 2207

## contextual & domain

- [HYBRID AUTOREGRESSIVE TRANSDUCER (HAT)](https://arxiv.org/abs/2003.07705), Ehsan Variani et al, Google, 2003

- [INTERNAL LANGUAGE MODEL TRAINING FOR DOMAIN-ADAPTIVE END-TO-END SPEECH RECOGNITION](https://arxiv.org/pdf/2102.01380.pdf), Zhong Meng et al, Microsoft, 2102

- [Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion](https://arxiv.org/abs/2104.02194), Duc Le et al, 2104

- [Investigating Methods to Improve Language Model Integration for Attention-based Encoder-Decoder ASR Models](https://arxiv.org/abs/2104.05544), Mohammad Zeineldeen et al, RWTH, 2104

- [Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition](https://arxiv.org/abs/2109.00627), Guangzhi Sun et al, 2109

- [INTEGRATING CATEGORICAL FEATURES IN END-TO-END ASR](https://arxiv.org/pdf/2110.03047.pdf), Rongqing Huang et al, 2110

- [CONTEXT-AWARE TRANSFORMER TRANSDUCER FOR SPEECH RECOGNITION](https://arxiv.org/pdf/2111.03250.pdf), Feng-Ju Chang et al, Amazon, 2111

- [CONSISTENT TRAINING AND DECODING FOR END-TO-END SPEECH RECOGNITION USING LATTICE-FREE MMI](https://arxiv.org/pdf/2112.02498.pdf), Jinchuan Tian et al, 2112

- [Improving Mandarin End-to-End Speech Recognition with Word N-gram Language Model](https://arxiv.org/pdf/2201.01995.pdf), Jinchuan Tian et al, 2201

- [KNOWLEDGE TRANSFER FROM LARGE-SCALE PRETRAINED LANGUAGE MODELS TO END-TO-END SPEECH RECOGNIZERS](https://arxiv.org/pdf/2202.07894.pdf), Yotaro Kubo et al, Google, 2202

## multilingual & accent

- [Scaling End-to-End Models for Large-Scale Multilingual ASR](https://arxiv.org/abs/2104.14830), Bo Li et al, 2104

- [A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English](https://arxiv.org/abs/2108.01280), Saida Mussakhojayeva et al, 2108

- [Multilingual Speech Recognition for Low-Resource Indian Languages using Multi-Task conformer](https://arxiv.org/abs/2109.03969), Krishna D N et al, 2109

- [ACCENT-ROBUST AUTOMATIC SPEECH RECOGNITION USING SUPERVISED AND UNSUPERVISED WAV2VEC EMBEDDINGS](https://arxiv.org/pdf/2110.03520.pdf), Jialu Li et al, Facebook, 2110


## code-switching

- [Acoustic data augmentation for Mandarin-English code-switching speech recognition](https://sci-hub.hkvisa.net/10.1016/j.apacoust.2019.107175), Yanhua Long et al, 1911

- [Bi-encoder Transformer Network for Mandarin-English Code-switching Speech Recognition using Mixture of Experts](https://speechlab.sjtu.edu.cn/papers/2020/yzl23-lu-is2020.pdf), Yizhou Lu et al, 2005

- [MANDARIN-ENGLISH CODE-SWITCHING SPEECH RECOGNITION WITH SELF-SUPERVISED SPEECH REPRESENTATION MODELS](https://arxiv.org/pdf/2110.03504.pdf), Liang-Hsuan Tseng et al, 2110

- [Integrating Knowledge in End-to-End Automatic Speech Recognition for Mandarin-English Code-Switching](https://arxiv.org/pdf/2112.10202.pdf), Chia-Yu Li et al, 2112


## unsupervised & semi-supervised & self-supervised

- [Unsupervised Cross-lingual Representation Learning for Speech Recognition](https://arxiv.org/abs/2006.13979), Alexis Conneau et al, 2006

- [Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition](https://arxiv.org/abs/2010.10504), Yu Zhang et al, 2010

- [Unsupervised Speech Recognition](https://arxiv.org/abs/2105.11084), Alexei Baevski et al, 2105

- [Unsupervised Automatic Speech Recognition : A Review](https://arxiv.org/abs/2106.04897), Hanan Aldarmaki et al, 2106

- [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447), Wei-Ning Hsu et al, 2106

- [BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition](https://arxiv.org/abs/2109.13226), Yu Zhang et al, 2109

- [IMPROVING PSEUDO-LABEL TRAINING FOR END-TO-END SPEECH RECOGNITION USING GRADIENT MASK](https://arxiv.org/pdf/2110.04056.pdf), Shaoshi Ling et al, Bytedance, 2110

- [WORD ORDER DOES NOT MATTER FOR SPEECH RECOGNITION](https://arxiv.org/pdf/2110.05994.pdf), Vineel Pratap et al, 2110

- [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing](https://arxiv.org/pdf/2110.13900.pdf), Sanyuan Chen et al, 2110

- [Pseudo-Labeling for Massively Multilingual Speech Recognition](https://arxiv.org/abs/2111.00161), Loren Lugosch et al, Facebook, 2111

- [SCALING ASR IMPROVES ZERO AND FEW SHOT LEARNING](https://arxiv.org/pdf/2111.05948.pdf), Alex Xiao et al, Facebook, 2111

- [EFFICIENT ADAPTER TRANSFER OF SELF-SUPERVISED SPEECH MODELS FOR AUTOMATIC SPEECH RECOGNITION](https://arxiv.org/pdf/2202.03218.pdf), Bethan Thomas et al, 2202

- [Towards End-to-end Unsupervised Speech Recognition](https://arxiv.org/pdf/2204.02492.pdf), Alexander H. Liu et al, Facebook, 2204

## confidence estimation

- [Confidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural Networks](https://arxiv.org/pdf/1910.11933.pdf), A. Kastanos et al, 1910

- [CONFIDENCE ESTIMATION FOR ATTENTION-BASED SEQUENCE-TO-SEQUENCE MODELS FOR SPEECH RECOGNITION](https://arxiv.org/pdf/2010.11428v2.pdf), Qiujia Li et al, Google, 2010

- [Residual Energy-Based Models for End-to-End Speech Recognition](https://arxiv.org/pdf/2103.14152v1.pdf), Qiujia Li et al, Google, 2103

- [Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction](https://arxiv.org/pdf/2104.12870.pdf), David Qiu et al, Google, 2104

- [IMPROVING CONFIDENCE ESTIMATION ON OUT-OF-DOMAIN DATA FOR END-TO-END SPEECH RECOGNITION](https://arxiv.org/pdf/2110.03327.pdf), Qiujia Li et al, Google, 2110

##  error correction

- [FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition](https://arxiv.org/pdf/2109.14420.pdf), Yichong Leng et al, 2109

## review & survey

- [On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition](https://arxiv.org/abs/2005.14327), Jinyu Li et al, 2005

- [Adaptation Algorithms for Neural Network-Based Speech Recognition: An Overview](https://arxiv.org/abs/2008.06580), Peter Bell et al, 2008

- [Automatic speech recognition: a survey](https://link.springer.com/article/10.1007/s11042-020-10073-7), Mishaim Malik et al, 2011

- [A REVIEW OF ON-DEVICE FULLY NEURAL END-TO-END AUTOMATIC SPEECH RECOGNITION ALGORITHMS](https://arxiv.org/abs/2012.07974), Chanwoo Kim et al, 2012

- [Thank you for Attention: A survey on Attention-based Artificial Neural Networks for Automatic Speech Recognition](https://arxiv.org/abs/2102.07259), Priyabrata Karmakar et al, 2102

- [Accented Speech Recognition: A Survey](https://arxiv.org/abs/2104.10747), Arthur Hinsvark et al, 2104

- [The History of Speech Recognition to the Year 2030](https://arxiv.org/abs/2108.00084), Awni Hannun et al, 2108

- [Automatic Speech Recognition using limited vocabulary: A survey](https://arxiv.org/abs/2108.10254), JEAN LOUIS K. E. FENDJI et al, 2108

- [Recent Advances in End-to-End Automatic Speech Recognition](https://arxiv.org/pdf/2111.01690.pdf), JINYU LI et al, 2111


## other list of speech recognition

- [speech-recognition-papers](https://github.com/wenet-e2e/speech-recognition-papers)
