# ASR Paper

## data augmentation

- [SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition](https://arxiv.org/pdf/1904.08779.pdf), Daniel S. Park et al, Google, 1904

- [SPLICEOUT: A Simple and Efficient Audio Augmentation Method](https://arxiv.org/pdf/2110.00046.pdf), Arjit Jain et al, 2109

## transformer

- [Transformers with convolutional context for ASR](https://arxiv.org/abs/1904.11660), Abdelrahman Mohamed et al, Facebook, 1904 

- [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100), Anmol Gulati et al, Google, 2005

- [SIMPLIFIED SELF-ATTENTION FOR TRANSFORMER-BASED END-TO-END SPEECH RECOGNITION](https://arxiv.org/abs/2005.10463), Haoneng Luo et al, 2005

- [Advanced Long-context End-to-end Speech Recognition Using Context-expanded Transformers](https://arxiv.org/abs/2104.09426), Takaaki Hori et al, 2104

- [A Survey of Transformers](https://arxiv.org/abs/2106.04554), Tianyang Lin et al, 2106

## transducer

- [TRANSFORMER-TRANSDUCER: END-TO-END SPEECH RECOGNITION WITH SELF-ATTENTION](https://arxiv.org/abs/1910.12977), Ching-Feng Yeh et al, 1910

- [IMPROVING ACCURACY OF RARE WORDS FOR RNN-TRANSDUCER THROUGH UNIGRAM SHALLOW FUSION](https://arxiv.org/abs/2012.00133), Vijay Ravi et al, 2012

- [LESS IS MORE: IMPROVED RNN-T DECODING USING LIMITED LABEL CONTEXT AND PATH MERGING](https://arxiv.org/abs/2012.06749), Rohit Prabhavalkar et al, 2012

## streaming

- [A BETTER AND FASTER END-TO-END MODEL FOR STREAMING ASR](https://arxiv.org/abs/2011.10798), Bo Li et al, 2011

- [Bridging the gap between streaming and non-streaming ASR systems by distilling ensembles of CTC and RNN-T models](https://arxiv.org/abs/2104.14346), Thibault Doutre et al, 2104

- [Reducing Streaming ASR Model Delay with Self Alignment](https://arxiv.org/abs/2105.05005), Jaeyoung Kim et al, 2105

- [Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models](https://arxiv.org/abs/2107.09428), Tianzi Wang et al, 2107


## cascaded

- [Modular End-to-end Automatic Speech Recognition Framework for Acoustic-to-word Model](https://arxiv.org/pdf/2008.00953.pdf), Qi Liu et al, 2008

- [TRANSFORMER TRANSDUCER: ONE MODEL UNIFYING STREAMING AND NON-STREAMING SPEECH RECOGNITION](https://arxiv.org/abs/2010.03192), Anshuman Tripathi et al, 2010

- [UNIVERSAL ASR: UNIFYING STREAMING AND NON-STREAMING ASR USING A SINGLE ENCODER-DECODER MODEL](https://arxiv.org/abs/2010.14099), Zhifu Gao et al, 2010

- [CASCADED ENCODERS FOR UNIFYING STREAMING AND NON-STREAMING ASR](https://arxiv.org/abs/2010.14606), Arun Narayanan et al, 2010

- [CASCADE RNN-TRANSDUCER: SYLLABLE BASED STREAMING ON-DEVICE MANDARIN SPEECH RECOGNITION WITH A SYLLABLE-TO-CHARACTER CONVERTER](https://arxiv.org/abs/2011.08469), Xiong Wang et al, 2011

- [Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition](https://arxiv.org/abs/2012.05481), Binbin Zhang, 2012

- [TRANSFORMER BASED DELIBERATION FOR TWO-PASS SPEECH RECOGNITION](https://arxiv.org/abs/2101.11577), Ke Hu et al, 2101

- [TSNAT: Two-Step Non-Autoregressvie Transformer Models for Speech Recognition](https://arxiv.org/abs/2104.01522), Zhengkun Tian et al, 2104

- [DECOUPLING RECOGNITION AND TRANSCRIPTION IN MANDARIN ASR](https://arxiv.org/abs/2108.01129), Jiahong Yuan et al, 2108

## contextual & domain

- [HYBRID AUTOREGRESSIVE TRANSDUCER (HAT)](https://arxiv.org/abs/2003.07705), Ehsan Variani et al, 2003

- [Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion](https://arxiv.org/abs/2104.02194), Duc Le et al, 2104

- [Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition](https://arxiv.org/abs/2109.00627), Guangzhi Sun et al, 2109

- [INTEGRATING CATEGORICAL FEATURES IN END-TO-END ASR](https://arxiv.org/pdf/2110.03047.pdf), Rongqing Huang et al, 2110

## multilingual & accent

- [Scaling End-to-End Models for Large-Scale Multilingual ASR](https://arxiv.org/abs/2104.14830), Bo Li et al, 2104

- [A Study of Multilingual End-to-End Speech Recognition for Kazakh, Russian, and English](https://arxiv.org/abs/2108.01280), Saida Mussakhojayeva et al, 2108

- [Multilingual Speech Recognition for Low-Resource Indian Languages using Multi-Task conformer](https://arxiv.org/abs/2109.03969), Krishna D N et al, 2109

- [ACCENT-ROBUST AUTOMATIC SPEECH RECOGNITION USING SUPERVISED AND UNSUPERVISED WAV2VEC EMBEDDINGS](https://arxiv.org/pdf/2110.03520.pdf), Jialu Li et al, Facebook, 2110


## code-switching

- [Bi-encoder Transformer Network for Mandarin-English Code-switching Speech Recognition using Mixture of Experts](https://speechlab.sjtu.edu.cn/papers/2020/yzl23-lu-is2020.pdf), Yizhou Lu et al, 2005

- [MANDARIN-ENGLISH CODE-SWITCHING SPEECH RECOGNITION WITH SELF-SUPERVISED SPEECH REPRESENTATION MODELS](https://arxiv.org/pdf/2110.03504.pdf), Liang-Hsuan Tseng et al, 2110


## unsupervised & semi-supervised & self-supervised

- [Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition](https://arxiv.org/abs/2010.10504), Yu Zhang et al, 2010

- [Unsupervised Speech Recognition](https://arxiv.org/abs/2105.11084), Alexei Baevski et al, 2105

- [Unsupervised Automatic Speech Recognition : A Review](https://arxiv.org/abs/2106.04897), Hanan Aldarmaki et al, 2106

- [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447), Wei-Ning Hsu et al, 2106

- [BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition](https://arxiv.org/abs/2109.13226), Yu Zhang et al, 2109


## confidence estimation

- [Confidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural Networks](https://arxiv.org/pdf/1910.11933.pdf), A. Kastanos et al, 1910

- [CONFIDENCE ESTIMATION FOR ATTENTION-BASED SEQUENCE-TO-SEQUENCE MODELS FOR SPEECH RECOGNITION](https://arxiv.org/pdf/2010.11428v2.pdf), Qiujia Li et al, Google, 2010

- [Residual Energy-Based Models for End-to-End Speech Recognition](https://arxiv.org/pdf/2103.14152v1.pdf), Qiujia Li et al, Google, 2103

- [Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction](https://arxiv.org/pdf/2104.12870.pdf), David Qiu et al, Google, 2104

- [IMPROVING CONFIDENCE ESTIMATION ON OUT-OF-DOMAIN DATA FOR END-TO-END SPEECH RECOGNITION](https://arxiv.org/pdf/2110.03327.pdf), Qiujia Li et al, Google, 2110

## review & survey

- [On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition](https://arxiv.org/abs/2005.14327), Jinyu Li et al, 2005

- [Adaptation Algorithms for Neural Network-Based Speech Recognition: An Overview](https://arxiv.org/abs/2008.06580), Peter Bell et al, 2008

- [Automatic speech recognition: a survey](https://link.springer.com/article/10.1007/s11042-020-10073-7), Mishaim Malik et al, 2011

- [A REVIEW OF ON-DEVICE FULLY NEURAL END-TO-END AUTOMATIC SPEECH RECOGNITION ALGORITHMS](https://arxiv.org/abs/2012.07974), Chanwoo Kim et al, 2012

- [Thank you for Attention: A survey on Attention-based Artificial Neural Networks for Automatic Speech Recognition](https://arxiv.org/abs/2102.07259), Priyabrata Karmakar et al, 2102

- [Accented Speech Recognition: A Survey](https://arxiv.org/abs/2104.10747), Arthur Hinsvark et al, 2104

- [The History of Speech Recognition to the Year 2030](https://arxiv.org/abs/2108.00084), Awni Hannun et al, 2108

- [Automatic Speech Recognition using limited vocabulary: A survey](https://arxiv.org/abs/2108.10254), JEAN LOUIS K. E. FENDJI et al, 2108

